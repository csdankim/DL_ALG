{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "# from tensorboardX import SummaryWriter  # for pytorch below 1.14\n",
    "from torch.utils.tensorboard import SummaryWriter # for pytorch above or equal 1.14\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32 #mini_batch size\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "## data augmentation for Q4\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "#     transforms.RandomRotation(10),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# images, labels = next(iter(trainloader))\n",
    "# writer = SummaryWriter(log_dir='./log')\n",
    "# # writer.add_images('images', grid)\n",
    "# writer.add_graph(net, [images.cuda()])\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# writer.add_images('images', grid)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "* Add a batch normalization layer after the first fully-connected layer(fc1) (8 points).\n",
    "* Save the model after training(Checkout our tutorial on how to save your model).\n",
    "Becareful that batch normalization layer performs differently between training and evalation process, make sure you understand how to convert your model between training mode and evaluation mode(you can find hints in my code).\n",
    "* Observe the difference of final training/testing accuracy with/without batch normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.bnorm = nn.BatchNorm1d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bnorm(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "* Modify our model by adding another fully connected layer with 512 nodes at the second-to-last layer (before the fc2 layer) (8 points).\n",
    "* Apply the model weights you saved at step 1 to initialize to the new model(only up to fc2 layer since after that all layers are newly created) before training. \n",
    "* Train and save the model (Hint: check the end of the assignment description to see how to partially restore weights from a pretrained weights file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q2-1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc_q2 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.bnorm = nn.BatchNorm1d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bnorm(x)\n",
    "        x = F.relu(self.fc_q2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2-2\n",
    "def partially_restore_weights(filepath):\n",
    "    pretrained_dict = torch.load(filepath)\n",
    "    model_dict = net.state_dict()\n",
    "    pretrained_dict = {key: val for key, val in pretrained_dict.items() if key in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    net.load_state_dict(model_dict)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "* Try to tune your network in another way (e.g. add/remove a layer, change the activation function, add/remove regularizer, change the number of hidden units, more batch normalization layers) not described in the previous four. You can start from random initialization or previous results as you wish (8 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc_q2 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.bnorm1d1 = nn.BatchNorm1d(512)\n",
    "        self.bnorm1d2 = nn.BatchNorm1d(512)\n",
    "        self.bnorm2d1 = nn.BatchNorm2d(32)\n",
    "        self.bnorm2d2 = nn.BatchNorm2d(64)\n",
    "        self.bnorm2d3 = nn.BatchNorm2d(128)\n",
    "#         self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift, https://arxiv.org/abs/1801.05134\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bnorm2d1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "#         x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bnorm2d2(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "#         x = self.dropout(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.bnorm2d3(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bnorm1d1(x)         \n",
    "        x = F.relu(self.fc_q2(x))\n",
    "        x = self.bnorm1d2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    net.eval() # Why would I do this?\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "    net.train() # Why would I do this?\n",
    "    return total_loss / total, correct.float() / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Building model...')\n",
    "net = Net().cuda()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc_q2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (bnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = partially_restore_weights('mytraining1.pth')\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "* Try to use an adaptive schedule to tune the learning rate, you can choose from RMSprop, Adagrad and Adam (Hint: you don't need to implement any of these, look at Pytorch documentation please) (8 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train() # Why would I do this?\n",
    "\n",
    "# writer = SummaryWriter(log_dir='./log')\n",
    "# writer.add_images('images', grid)\n",
    "# writer.add_graph(net, [images])\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid([images.cuda()])\n",
    "writer = SummaryWriter(log_dir='./log')\n",
    "writer.add_images('images', grid)\n",
    "writer.add_graph(net, [images.cuda()])\n",
    "# grid = torchvision.utils.make_grid([images.cuda()])\n",
    "# writer.add_images('images', grid)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.008) # Q3(lr=0.003) & Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "    Step:   500 avg_batch_loss: 2.01295\n",
      "    Step:  1000 avg_batch_loss: 1.52447\n",
      "    Step:  1500 avg_batch_loss: 1.31798\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 1 train_loss: 0.03434 train_acc: 0.60480 test_loss: 0.03535 test_acc 0.59190\n",
      "    Step:   500 avg_batch_loss: 1.10507\n",
      "    Step:  1000 avg_batch_loss: 0.99943\n",
      "    Step:  1500 avg_batch_loss: 0.93074\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 2 train_loss: 0.02455 train_acc: 0.72542 test_loss: 0.02841 test_acc 0.68330\n",
      "    Step:   500 avg_batch_loss: 0.76452\n",
      "    Step:  1000 avg_batch_loss: 0.75116\n",
      "    Step:  1500 avg_batch_loss: 0.72206\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 3 train_loss: 0.01721 train_acc: 0.80966 test_loss: 0.02465 test_acc 0.72890\n",
      "    Step:   500 avg_batch_loss: 0.54224\n",
      "    Step:  1000 avg_batch_loss: 0.56735\n",
      "    Step:  1500 avg_batch_loss: 0.56525\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 4 train_loss: 0.01161 train_acc: 0.87722 test_loss: 0.02335 test_acc 0.74610\n",
      "    Step:   500 avg_batch_loss: 0.35637\n",
      "    Step:  1000 avg_batch_loss: 0.42042\n",
      "    Step:  1500 avg_batch_loss: 0.41459\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 5 train_loss: 0.00744 train_acc: 0.92162 test_loss: 0.02539 test_acc 0.74460\n",
      "    Step:   500 avg_batch_loss: 0.22305\n",
      "    Step:  1000 avg_batch_loss: 0.26011\n",
      "    Step:  1500 avg_batch_loss: 0.30018\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 6 train_loss: 0.00563 train_acc: 0.94182 test_loss: 0.02875 test_acc 0.73400\n",
      "    Step:   500 avg_batch_loss: 0.15627\n",
      "    Step:  1000 avg_batch_loss: 0.20172\n",
      "    Step:  1500 avg_batch_loss: 0.22818\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 7 train_loss: 0.00387 train_acc: 0.95826 test_loss: 0.03216 test_acc 0.74280\n",
      "    Step:   500 avg_batch_loss: 0.11459\n",
      "    Step:  1000 avg_batch_loss: 0.16609\n",
      "    Step:  1500 avg_batch_loss: 0.18398\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 8 train_loss: 0.00460 train_acc: 0.94998 test_loss: 0.03935 test_acc 0.73410\n",
      "    Step:   500 avg_batch_loss: 0.12620\n",
      "    Step:  1000 avg_batch_loss: 0.14145\n",
      "    Step:  1500 avg_batch_loss: 0.16158\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 9 train_loss: 0.00394 train_acc: 0.95724 test_loss: 0.03981 test_acc 0.72870\n",
      "    Step:   500 avg_batch_loss: 0.09327\n",
      "    Step:  1000 avg_batch_loss: 0.11002\n",
      "    Step:  1500 avg_batch_loss: 0.13819\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 10 train_loss: 0.00295 train_acc: 0.97018 test_loss: 0.04239 test_acc 0.73590\n",
      "Finished Training\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 10 #maximum epoch to train\n",
    "\n",
    "print('Start training...')\n",
    "for epoch in range(MAX_EPOCH):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('    Step: %5d avg_batch_loss: %.5f' %\n",
    "                  (i + 1, running_loss / 500))\n",
    "            running_loss = 0.0\n",
    "    print('    Finish training this EPOCH, start evaluating...')\n",
    "    train_loss, train_acc = eval_net(trainloader)\n",
    "    test_loss, test_acc = eval_net(testloader)\n",
    "    print('EPOCH: %d train_loss: %.5f train_acc: %.5f test_loss: %.5f test_acc %.5f' %\n",
    "          (epoch+1, train_loss, train_acc, test_loss, test_acc))\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss)\n",
    "    writer.add_scalar('train_acc', train_acc)\n",
    "    writer.add_scalar('test_loss', test_loss)\n",
    "    writer.add_scalar('test_acc', test_acc)\n",
    "    \n",
    "\n",
    "writer.close()\n",
    "print('Finished Training')\n",
    "print('Saving model...')\n",
    "torch.save(net.state_dict(), 'mytraining6.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-27 11:48:56.801215: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-27 11:48:56.801276: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-27 11:48:56.801304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.1.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir ./"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
