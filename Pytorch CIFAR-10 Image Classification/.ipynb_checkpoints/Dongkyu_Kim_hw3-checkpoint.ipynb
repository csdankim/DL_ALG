{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "# from tensorboardX import SummaryWriter  # for pytorch below 1.14\n",
    "from torch.utils.tensorboard import SummaryWriter # for pytorch above or equal 1.14\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 32, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32 #mini_batch size\n",
    "\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "## data augmentation for Q4\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# images, labels = next(iter(trainloader))\n",
    "# writer = SummaryWriter(log_dir='./log')\n",
    "# # writer.add_images('images', grid)\n",
    "# writer.add_graph(net, [images.cuda()])\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# writer.add_images('images', grid)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# images.shape\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "* Add a batch normalization layer after the first fully-connected layer(fc1) (8 points).\n",
    "* Save the model after training(Checkout our tutorial on how to save your model).\n",
    "Becareful that batch normalization layer performs differently between training and evalation process, make sure you understand how to convert your model between training mode and evaluation mode(you can find hints in my code).\n",
    "* Observe the difference of final training/testing accuracy with/without batch normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.bnorm = nn.BatchNorm1d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bnorm(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "* Modify our model by adding another fully connected layer with 512 nodes at the second-to-last layer (before the fc2 layer) (8 points).\n",
    "* Apply the model weights you saved at step 1 to initialize to the new model(only up to fc2 layer since after that all layers are newly created) before training. \n",
    "* Train and save the model (Hint: check the end of the assignment description to see how to partially restore weights from a pretrained weights file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q2-1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc_q2 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.bnorm = nn.BatchNorm1d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bnorm(x)\n",
    "        x = F.relu(self.fc_q2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2-2\n",
    "def partially_restore_weights(filepath):\n",
    "    pretrained_dict = torch.load(filepath)\n",
    "    model_dict = net.state_dict()\n",
    "    pretrained_dict = {key: val for key, val in pretrained_dict.items() if key in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    net.load_state_dict(model_dict)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "* Try to tune your network in another way (e.g. add/remove a layer, change the activation function, add/remove regularizer, change the number of hidden units, more batch normalization layers) not described in the previous four. You can start from random initialization or previous results as you wish (8 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc_q2 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.bnorm1d1 = nn.BatchNorm1d(512)\n",
    "        self.bnorm1d2 = nn.BatchNorm1d(512)\n",
    "        self.bnorm2d1 = nn.BatchNorm2d(32)\n",
    "        self.bnorm2d2 = nn.BatchNorm2d(64)\n",
    "        self.bnorm2d3 = nn.BatchNorm2d(128)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift, https://arxiv.org/abs/1801.05134\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bnorm2d1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bnorm2d2(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.bnorm2d3(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bnorm1d1(x)         \n",
    "        x = F.relu(self.fc_q2(x))\n",
    "        x = self.bnorm1d2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    net.eval() # Why would I do this?\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "    net.train() # Why would I do this?\n",
    "    return total_loss / total, correct.float() / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc_q2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (bnorm1d1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnorm1d2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnorm2d1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnorm2d2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnorm2d3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Building model...')\n",
    "net = Net().cuda()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc_q2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (bnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = partially_restore_weights('mytraining1.pth')\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "* Try to use an adaptive schedule to tune the learning rate, you can choose from RMSprop, Adagrad and Adam (Hint: you don't need to implement any of these, look at Pytorch documentation please) (8 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train() # Why would I do this?\n",
    "\n",
    "# writer = SummaryWriter(log_dir='./log')\n",
    "# writer.add_images('images', grid)\n",
    "# writer.add_graph(net, [images])\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid([images.cuda()])\n",
    "writer = SummaryWriter(log_dir='./log')\n",
    "writer.add_images('images', grid)\n",
    "writer.add_graph(net, [images.cuda()])\n",
    "# grid = torchvision.utils.make_grid([images.cuda()])\n",
    "# writer.add_images('images', grid)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.008) # Q3(lr=0.003) & Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "    Step:   500 avg_batch_loss: 2.11746\n",
      "    Step:  1000 avg_batch_loss: 1.68849\n",
      "    Step:  1500 avg_batch_loss: 1.50488\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 1 train_loss: 0.04543 train_acc: 0.50974 test_loss: 0.04407 test_acc 0.50830\n",
      "    Step:   500 avg_batch_loss: 1.36257\n",
      "    Step:  1000 avg_batch_loss: 1.26922\n",
      "    Step:  1500 avg_batch_loss: 1.18455\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 2 train_loss: 0.03821 train_acc: 0.63264 test_loss: 0.03515 test_acc 0.63130\n",
      "    Step:   500 avg_batch_loss: 1.14673\n",
      "    Step:  1000 avg_batch_loss: 1.08889\n",
      "    Step:  1500 avg_batch_loss: 1.00440\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 3 train_loss: 0.03116 train_acc: 0.68860 test_loss: 0.03508 test_acc 0.68610\n",
      "    Step:   500 avg_batch_loss: 0.94828\n",
      "    Step:  1000 avg_batch_loss: 0.93662\n",
      "    Step:  1500 avg_batch_loss: 0.92538\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 4 train_loss: 2.35337 train_acc: 0.70798 test_loss: 1.73110 test_acc 0.69630\n",
      "    Step:   500 avg_batch_loss: 0.87089\n",
      "    Step:  1000 avg_batch_loss: 0.84650\n",
      "    Step:  1500 avg_batch_loss: 0.83067\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 5 train_loss: 5.33157 train_acc: 0.73740 test_loss: 9.77265 test_acc 0.72520\n",
      "    Step:   500 avg_batch_loss: 0.81208\n",
      "    Step:  1000 avg_batch_loss: 0.80017\n",
      "    Step:  1500 avg_batch_loss: 0.79571\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 6 train_loss: 2.46283 train_acc: 0.77072 test_loss: 0.70330 test_acc 0.76360\n",
      "    Step:   500 avg_batch_loss: 0.74695\n",
      "    Step:  1000 avg_batch_loss: 0.74339\n",
      "    Step:  1500 avg_batch_loss: 0.73718\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 7 train_loss: 7.88664 train_acc: 0.78888 test_loss: 4.99365 test_acc 0.77450\n",
      "    Step:   500 avg_batch_loss: 0.71557\n",
      "    Step:  1000 avg_batch_loss: 0.71639\n",
      "    Step:  1500 avg_batch_loss: 0.69919\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 8 train_loss: 33.22792 train_acc: 0.77956 test_loss: 9.47100 test_acc 0.75600\n",
      "    Step:   500 avg_batch_loss: 0.68343\n",
      "    Step:  1000 avg_batch_loss: 0.90425\n",
      "    Step:  1500 avg_batch_loss: 1.59381\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 9 train_loss: 1.99441 train_acc: 0.53242 test_loss: 262.48860 test_acc 0.52750\n",
      "    Step:   500 avg_batch_loss: 1.26956\n",
      "    Step:  1000 avg_batch_loss: 1.07865\n",
      "    Step:  1500 avg_batch_loss: 0.96404\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 10 train_loss: 3.89622 train_acc: 0.72810 test_loss: 0.87431 test_acc 0.71260\n",
      "Finished Training\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 10 #maximum epoch to train\n",
    "\n",
    "print('Start training...')\n",
    "for epoch in range(MAX_EPOCH):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('    Step: %5d avg_batch_loss: %.5f' %\n",
    "                  (i + 1, running_loss / 500))\n",
    "            running_loss = 0.0\n",
    "    print('    Finish training this EPOCH, start evaluating...')\n",
    "    train_loss, train_acc = eval_net(trainloader)\n",
    "    test_loss, test_acc = eval_net(testloader)\n",
    "    print('EPOCH: %d train_loss: %.5f train_acc: %.5f test_loss: %.5f test_acc %.5f' %\n",
    "          (epoch+1, train_loss, train_acc, test_loss, test_acc))\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch+1)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch+1)\n",
    "    writer.add_scalar('test_loss', test_loss, epoch+1)\n",
    "    writer.add_scalar('test_acc', test_acc, epoch+1)\n",
    "    \n",
    "\n",
    "writer.close()\n",
    "print('Finished Training')\n",
    "print('Saving model...')\n",
    "torch.save(net.state_dict(), 'mytraining5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-27 11:48:56.801215: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-27 11:48:56.801276: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-27 11:48:56.801304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.1.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir ./"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
